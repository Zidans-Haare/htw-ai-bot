# HTW ABC AI Bot

Dieses Projekt ist eine Node.js-Anwendung, die einen KI-gest√ºtzten Chat-Assistenten √ºber eine API bereitstellt. Es umfasst ein umfassendes Admin-Panel zur Verwaltung von Inhalten, ein Dashboard zur √úberwachung von Analysen und optionale Vektor-Datenbank-Unterst√ºtzung f√ºr erweiterte semantische Suche. Die Anwendung l√§uft live unter [aski.htw-dresden.de](https://aski.htw-dresden.de).

## ‚ú® Features

- **KI-Chat:** Eine √∂ffentliche Schnittstelle (`/api/chat`), die Anfragen √ºber verschiedene KI-Provider (OpenAI + kompatible APIs wie universit√§re ChatAI, Google Gemini, Claude, XAI) beantwortet.
- **Admin-Panel:** Eine passwortgesch√ºtzte Weboberfl√§che zur Verwaltung von Hochschul-ABC-Eintr√§gen, Benutzern, Bildern, Dokumenten und zur √úberpr√ºfung von Feedback.
- **Dashboard:** Ein separates, gesch√ºtztes Dashboard zur Anzeige von Nutzungsstatistiken und Anwendungsdaten.
- **Vektor-Datenbank:** Optionale Unterst√ºtzung f√ºr ChromaDB oder Weaviate zur semantischen Suche in Dokumenten und Bildern.
- **Embeddings:** Konfigurierbare Text-Einbettungen mit Xenova oder Hugging Face Modellen f√ºr erweiterte KI-Funktionen.
- **Sicherheit:** Die Anwendung verwendet `helmet` zur Absicherung von HTTP-Headern und `express-rate-limit` zum Schutz vor Brute-Force-Angriffen.
- **Authentifizierung:** Admin- und Dashboard-Bereiche sind durch eine sitzungsbasierte Authentifizierung gesch√ºtzt.

## üíª Technologie-Stack

- **Backend:** Node.js, Express.js
- **Datenbank:** SQLite (Standard) √ºber Prisma ORM; optional PostgreSQL/MySQL via `DATABASE_URL`
- **Vektor-DB:** Optional ChromaDB oder Weaviate f√ºr semantische Suche
- **Embeddings:** Xenova Transformers oder Hugging Face f√ºr Text-Einbettungen
- **Frontend:** Statisches HTML, CSS und JavaScript (gebaut mit Vite)
- **KI:** Mehrere Provider (OpenAI + kompatible APIs wie universit√§re ChatAI, Google Gemini, Anthropic Claude, XAI)

## üöÄ Setup & Konfiguration

### Voraussetzungen

- Node.js (Version 18 oder neuer)
- npm (wird mit Node.js installiert)

### Installation

1.  **Abh√§ngigkeiten installieren:**

    F√ºr grundlegende Funktionalit√§t (ohne KI-Provider, Vektor-DBs usw.):
    ```bash
    npm install --production --no-optional
    ```

    F√ºr vollst√§ndige Installation (mit allen optionalen Abh√§ngigkeiten):
    ```bash
    npm install
    ```

    **Optionale Abh√§ngigkeiten:** Die folgenden Pakete werden nur installiert, wenn die entsprechenden Features verwendet werden (z. B. √ºber Umgebungsvariablen):
    - `@google/generative-ai`: F√ºr Google Gemini (wenn `AI_PROVIDER=google`).
    - `@anthropic-ai/sdk`: F√ºr Anthropic Claude (wenn `AI_PROVIDER=claude`).
    - `@huggingface/transformers`: F√ºr Hugging Face Embeddings (wenn `EMBEDDING_LIBRARY=huggingface`).
    - `@langchain/community`: F√ºr LangChain-Community-Integrationen.
    - `@langchain/core`: Kernbibliothek f√ºr LangChain.
    - `@langchain/openai`: LangChain-Integration f√ºr OpenAI.
    - `@langchain/textsplitters`: Textaufteilung f√ºr LangChain.
    - `@xenova/transformers`: F√ºr Xenova Embeddings (wenn `EMBEDDING_LIBRARY=xenova`).
    - `chromadb`: F√ºr ChromaDB als Vektor-Datenbank (wenn `VECTOR_DB_TYPE=chroma`).
    - `langchain`: LangChain-Bibliothek.
    - `mysql2`: F√ºr MySQL-Datenbank (wenn `MAIN_DB_TYPE=mysql`).
    - `openai`: Offizielle OpenAI-API-Bibliothek (wenn `AI_PROVIDER=openai`).
    - `pg`: F√ºr PostgreSQL-Datenbank (wenn `MAIN_DB_TYPE=postgresql`).
    - `weaviate-client`: F√ºr Weaviate als Vektor-Datenbank (wenn `VECTOR_DB_TYPE=weaviate`).

2.  **Konfiguration:**
    Erstellen Sie eine `.env`-Datei im Projektstammverzeichnis basierend auf `.env.example`. Kopieren Sie `.env.example` nach `.env` und passen Sie die Werte an.

    Die wichtigsten Umgebungsvariablen sind:

    ```env
    # ========================================================================================
    # AI CHAT CONFIGURATION [REQUIRED]
    # ========================================================================================

    # AI Provider Selection [REQUIRED]
    # Options: openai (official OpenAI + compatible APIs like university chatAi), google (Gemini), claude (Anthropic), xai
    AI_PROVIDER=openai

    # Primary API Key [REQUIRED] - Used for the selected AI_PROVIDER above
    AI_API_KEY=dein-api-key

    # Base URL for API calls [OPTIONAL] - Required for chatAi and xai providers
    AI_BASE_URL=https://chat-ai.academiccloud.de/v1

    # AI Model Selection [OPTIONAL] - Uses provider default if not specified
    AI_MODEL=openai-gpt-oss-120b

    # Response Temperature [OPTIONAL] - Controls randomness (0.0 = deterministic, 2.0 = very random)
    # Range: 0.0 - 2.0, Default: 0.2
    AI_TEMPERATURE=0.2

    # Maximum Response Tokens [OPTIONAL] - Limits response length
    # Default: 1000
    AI_MAX_TOKENS=2000

    # Enable Streaming Responses [OPTIONAL] - Send responses as they are generated
    # Options: true, false, Default: true
    AI_STREAMING=true

    # ========================================================================================
    # BACKEND AI CONFIGURATION [OPTIONAL]
    # ========================================================================================
    # Option to use separate settings for the backend part of the app

    # BACKEND_AI_PROVIDER=
    # BACKEND_AI_API_KEY=
    # BACKEND_AI_BASE_URL=
    # BACKEND_AI_OPENAI_BASE_URL=
    # BACKEND_AI_XAI_BASE_URL=
    # BACKEND_AI_MODEL=
    # BACKEND_AI_TEMPERATURE=
    # BACKEND_AI_MAX_TOKENS=8000

    # ========================================================================================
    # SERVER CONFIGURATION [OPTIONAL]
    # ========================================================================================

    # Server Port [OPTIONAL] - Port for the Express server to listen on
    # Default: 3000
    PORT=3000

    # Trust Proxy Count [OPTIONAL] - Number of proxy layers (e.g., Cloudflare + Nginx)
    # Default: 2
    TRUST_PROXY_COUNT=2

    # ========================================================================================
    # DATABASE CONFIGURATION [REQUIRED]
    # ========================================================================================

    # Main Database Connection [REQUIRED] - Supports SQLite, PostgreSQL, and MySQL
    # SQLite (default - file-based, no server required):
    DATABASE_URL="file:/home/htw/htc-abc-ai-bot/hochschul-abc.db"

    # PostgreSQL example:
    DATABASE_URL="postgresql://username:password@localhost:5432/dbname?schema=public"

    # MySQL example:
    # DATABASE_URL="mysql://username:password@localhost:3306/dbname"

    # ========================================================================================
    # BACKUP & DATABASE SWITCHING
    # ========================================================================================

    ## Backup-Prozess

    Die Anwendung bietet ein integriertes Backup-System f√ºr Daten und Dateien √ºber das Admin-Panel (`/admin/backup`).

    ### Backup erstellen:
    1. Melden Sie sich im Admin-Panel an.
    2. Gehen Sie zum Backup-Bereich.
    3. W√§hlen Sie die zu sichernden Tabellen (z. B. users, artikels, fragen, conversations, dokumente, bilder, feedback, dashboard).
    4. Klicken Sie auf "Backup erstellen" - eine ZIP-Datei wird in `backups/` gespeichert.

    ### Backup wiederherstellen:
    1. Laden Sie die ZIP-Datei √ºber "Backup hochladen" hoch oder verwenden Sie eine vorhandene Datei.
    2. W√§hlen Sie den Import-Modus:
       - **replace**: L√∂scht vorhandene Daten und ersetzt sie komplett.
       - **append-override**: F√ºgt hinzu und √ºberschreibt vorhandene Eintr√§ge.
       - **append-keep**: F√ºgt nur neue Eintr√§ge hinzu, beh√§lt vorhandene.
    3. W√§hlen Sie die zu importierenden Tabellen.
    4. Klicken Sie auf "Importieren".

    **Hinweise:**
    - Backups enthalten JSON-Daten und Dateien (Bilder, Dokumente).
    - Bei Schema-Unterschieden wird eine Warnung angezeigt, aber der Import fortgesetzt.
    - Tempor√§re Dateien werden automatisch bereinigt.
    - Backups sind nach Erstellungsdatum sortiert (neueste zuerst).

    ### Backup-Verwaltung:
    - Liste aller Backups anzeigen und herunterladen.
    - Backups umbenennen oder l√∂schen.

    ## Datenbank wechseln (SQLite ‚Üî PostgreSQL/MySQL)

    Die Anwendung unterst√ºtzt SQLite (Standard), PostgreSQL und MySQL. Um die Datenbank zu wechseln:

    1. **Schema aktualisieren:**
       √Ñndern Sie in `prisma/schema.prisma` den `provider`:
       ```prisma
       datasource db {
         provider = "postgresql"  // oder "mysql" oder "sqlite"
         url      = env("DATABASE_URL")
       }
       ```

    2. **Umgebungsvariablen aktualisieren:**
       √Ñndern Sie in `.env` die `DATABASE_URL`:
       - SQLite: `DATABASE_URL="file:/path/to/db.db"`
       - PostgreSQL: `DATABASE_URL="postgresql://user:pass@host:5432/dbname?schema=public"`
       - MySQL: `DATABASE_URL="mysql://user:pass@host:3306/dbname"`

    3. **Datenbank anwenden:**
       ```bash
       npx prisma db push  # Erstellt Tabellen in der neuen DB
       npx prisma generate  # Regeneriert den Prisma-Client
       ```

    4. **Daten migrieren (optional):**
       - Bei Wechsel von SQLite zu PostgreSQL/MySQL: Exportieren Sie Daten manuell (z. B. via Backup) und importieren Sie in die neue DB.
       - Prisma migriert keine Daten zwischen verschiedenen Providern automatisch.

    5. **Server neu starten:**
       ```bash
       npm run build
       pm2 restart ecosystem.config.js  # oder npm start
       ```

    **Wichtig:** Sichern Sie Ihre Daten vor dem Wechsel. Testen Sie die Konfiguration in einer Entwicklungsumgebung.

    # ========================================================================================
    # SESSION & AUTHENTICATION [OPTIONAL]
    # ========================================================================================

    # Session Inactivity Timeout [OPTIONAL] - Minutes after last activity before session expires
    # Also sets client-side cookie expiration. Default: 1440 (24 hours)
    SESSION_INACTIVITY_TIMEOUT_MINUTES=1440

    # Maximum Session Duration [OPTIONAL] - Maximum minutes from session creation
    # Default: 43200 (30 days)
    SESSION_MAX_DURATION_MINUTES=43200

    # ========================================================================================
    # VECTOR DATABASE CONFIGURATION [OPTIONAL]
    # ========================================================================================
    # Used for document embeddings and semantic search

    # Vector Database Type [OPTIONAL] - Enable vector database for advanced features
    # Options: none (default), chroma, weaviate
    VECTOR_DB_TYPE=none

    # ChromaDB Configuration [REQUIRED if VECTOR_DB_TYPE=chroma]
    CHROMA_URL=http://localhost:8000
    CHROMA_COLLECTION=htw-kb

    # Weaviate Configuration [REQUIRED if VECTOR_DB_TYPE=weaviate]
    WEAVIATE_URL=http://localhost:8080
    WEAVIATE_API_KEY=your-optional-key  # Anonymous for dev
    WEAVIATE_COLLECTION=htw-kb

    # ========================================================================================
    # EMBEDDING CONFIGURATION [OPTIONAL]
    # ========================================================================================
    # Used when VECTOR_DB_TYPE is enabled

    # Embedding Library [OPTIONAL] - Library for generating text embeddings
    # Options: none (default), huggingface, openai
    EMBEDDING_LIBRARY=xenova

    # ========================================================================================
    # ADVANCED/CUSTOM SETTINGS
    # ========================================================================================

    # Image List Mode for AI (static|simple|dynamic)
    USE_VECTOR_IMAGES=static

    # HuggingFace token for embeddings (required if EMBEDDING_LIBRARY=huggingface)
    HF_TOKEN=hf_...

    # Embedding Model Configuration
    EMBEDDING_MODEL=all-MiniLM-L12-v2
    EMBEDDING_DIMENSION=384
    EMBEDDING_POOLING=mean
    EMBEDDING_NORMALIZE=true

    # Vector DB Sync Settings
    VECTORDB_LAST_SYNC=0
    CHUNK_SIZE=500  # Tokens per chunk (best practice: 200-1000 for RAG)
    CHUNK_OVERLAP=50  # Overlap for context (prevents split sentences)
    RETRIEVE_K=3  # Num chunks to retrieve (balance precision/tokens)
    MIN_SIMILARITY=0.7  # Confidence threshold (cosine score; filter low-relevance)
    SYNC_ON_START=false  # Auto-sync headlines on server boot (for dev; false in prod)

    # GraphRAG Toggle (requires vector DB)
    ENABLE_GRAPHRAG=false  # Set true for graph extraction
    PDF_CHUNK_SIZE=300  # Chunk size for PDF text extraction
    PDF_EXTRACT_TEXT_ONLY=false  # Set true to skip images in PDF extraction
    SYNC_BATCH=100  # Batch size for vector DB sync to avoid OOM
    DISPLAY_TOKEN_USED_FOR_QUERY=true  # Set true to show tokens sent/received in chat UI

    # ========================================================================================
    # DEVELOPMENT & DEBUGGING [OPTIONAL]
    # ========================================================================================

    # Domain for CORS and links [OPTIONAL] - Used in development
    DOMAIN=http://localhost:3000

    # Upload Size Limit [OPTIONAL] - Maximum upload size in MB
    # Default: 10 (production: 50)
    UPLOAD_LIMIT_MB=50
    ```

3.  **Datenbank-Initialisierung:**
     Die Anwendung verwendet Prisma f√ºr die Datenbankverwaltung. Beim ersten Start wird die Datenbank automatisch mit Tabellen und Views erstellt. Bei Versions√§nderungen (z. B. nach Schema-Updates) werden Migrationen automatisch angewendet.

     - **Neue Datenbank:** Wenn keine `hochschuhl-abc.db` vorhanden ist, f√ºhrt die Anwendung `prisma db push` aus, um die Datenbank mit dem aktuellen Schema zu initialisieren.
     - **Versions√§nderungen:** Bei √Ñnderungen der App-Version (in `package.json`) oder fehlender Versionsverfolgung wird `prisma migrate deploy` ausgef√ºhrt, um ausstehende Migrationen anzuwenden (falls vorhanden).
     - **Manuelle Migration:** F√ºr manuelle Anpassungen verwenden Sie `npx prisma migrate dev --name beschreibung`.

4.  **Server starten:**
    F√ºr Produktion ist PM2 der empfohlene Weg, um den Server zu starten und √Ñnderungen an `.env` automatisch zu √ºberwachen und neu zu starten.

    ```bash
    # Zuerst das Projekt bauen
    npm run build

    # Dann mit PM2 starten (√ºberwacht .env f√ºr √Ñnderungen)
    pm2 start ecosystem.config.js
    ```

    Dies stellt sicher, dass der Server bei √Ñnderungen an Umgebungsvariablen (z. B. `VECTOR_DB_TYPE=chroma`) automatisch neu startet, ohne manuelles Eingreifen. PM2 begrenzt automatische Neustarts bei Abst√ºrzen auf 30 Versuche mit 5 Sekunden Verz√∂gerung; manuelle oder watch-basierte Neustarts sind unbegrenzt.

    F√ºr Entwicklung:
    ```bash
    npm run dev:watch
    ```
    Dies startet den Server mit Hot-Reload f√ºr Code- und `.env`-√Ñnderungen.

    F√ºr Tests:
    ```bash
    npm test
    ```
    F√ºhrt die Testsuite aus (interaktiv oder direkt).
    USE_VECTOR_IMAGES=static  # Image list mode for AI: 'static' (default, from DB), 'simple' (from vector DB), 'dynamic' (per-query from vector DB)

    # Vector DB Processing Options
    CHUNK_SIZE=500  # Size of text chunks for vectorization (200-1000, default: 500)
    CHUNK_OVERLAP=50  # Overlap between chunks (0-200, default: 50)
    RETRIEVE_K=3  # Number of similar chunks to retrieve (1-10, default: 3)
    MIN_SIMILARITY=0.7  # Minimum similarity score for retrieval (0-1, default: 0.7)
    EMBEDDING_LIBRARY=xenova  # Embedding library: 'xenova' (default, uses @xenova/transformers) or 'huggingface' (uses @huggingface/transformers)
    SYNC_ON_START=false  # Sync vector DB on startup: 'true' or 'false' (default: false)
    ENABLE_GRAPHRAG=false  # Enable graph-based retrieval: 'true' or 'false' (default: false)

    # PDF Processing Options
    PDF_CHUNK_SIZE=300  # Chunk size for PDF text (100-1000, default: 300)
    PDF_EXTRACT_TEXT_ONLY=false  # Extract only text from PDFs: 'true' or 'false' (default: false)
    SYNC_BATCH=100  # Batch size for vector DB sync (10-500, default: 100)
    DISPLAY_TOKEN_USED_FOR_QUERY=false  # Display token usage in responses: 'true' or 'false' (default: false)

    # Image Handling Options
    # The AI can reference images in responses. Configure how the image list is generated for the AI prompt.
    # - 'static': Fetch from main DB (Prisma). Fast, no vector DB required. Includes all images with descriptions.
    # - 'simple': Fetch from vector DB. Uses embeddings for retrieval, may improve relevance but adds latency.
    # - 'dynamic': Query vector DB per user question. Most adaptive, but highest latency and token usage.
    # Requires VECTOR_DB_TYPE != 'none' for 'simple'/'dynamic'. Fallbacks to 'static' if vector DB fails.

    # Embedding Models (known working models with dimensions)
    # For EMBEDDING_LIBRARY=xenova (default):
    # - all-MiniLM-L6-v2 (384 dimensions)
    # - paraphrase-multilingual-MiniLM-L12-v2 (384 dimensions)
    # For EMBEDDING_LIBRARY=huggingface:
    # - onnx-community/Qwen3-Embedding-0.6B-ONNX (1024 dimensions)
    # - sentence-transformers/all-MiniLM-L6-v2 (384 dimensions)
    ```

## ‚ñ∂Ô∏è Anwendung starten

### Entwicklung (Watcher-Bundle)

```bash
npm run dev:watch
```

- Baut das Frontend kontinuierlich (`vite build --watch`) und startet den Express-Server mit `nodemon`.
- √Ñnderungen in `src/` erzeugen sofort ein neues Bundle; √Ñnderungen unter `server/` l√∂sen einen automatischen Neustart aus.
- Die Anwendung l√§uft anschlie√üend unter `http://127.0.0.1:3000/`. Hot Module Reloading ist nicht notwendig, weil die neu gebauten Assets direkt von Express ausgeliefert werden.

### Produktion / Staging

```bash
npm run build
pm2 start ecosystem.config.js
```

- `npm run build` erstellt einmalig das Bundle unter `dist/`.
- `pm2 start ecosystem.config.js` startet den Express-Server mit PM2, welcher √Ñnderungen an `.env` √ºberwacht und automatisch neu startet. F√ºr Dauerbetrieb und automatische Neustarts bei Umgebungsvariablen-√Ñnderungen empfohlen.
- Alternativ `npm start` f√ºr einfache Starts ohne PM2, aber ohne automatische `.env`-√úberwachung.

### Nginx-Konfiguration (Beispiel f√ºr aski.htw-dresden.de)

F√ºr die Produktionsumgebung kann Nginx als Reverse-Proxy verwendet werden. Hier ein Beispiel f√ºr die Konfiguration in `/etc/nginx/sites-available/dev`:

```nginx
server {
    listen 80;
    server_name aski.htw-dresden.de;
    return 301 https://$host$request_uri;
}

server {
    listen 443 ssl http2;
    server_name aski.htw-dresden.de;

    ssl_certificate     /etc/nginx/ssl/origin.crt;
    ssl_certificate_key /etc/nginx/ssl/origin.key;
    include snippets/ssl-params.conf;

    # Disable separate route to uploads, because marginal gains vs complexity
    # location /uploads/ {
    #    alias /home/htw/htc-abc-ai-bot/uploads/;
    #    add_header Cache-Control "no-cache";
    # }

    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

Diese Konfiguration leitet HTTP-Anfragen auf HTTPS um und proxied alle Anfragen an den lokalen Express-Server auf Port 3000.

## üîê Authentifizierung

Der Zugriff auf das Admin-Panel (`/admin/`) und das Dashboard (`/dash/`) erfordert eine Anmeldung. Die Anwendung verwendet ein In-Memory-Session-Management.

-   **Wichtiger Hinweis:** Da die Sitzungen im Speicher gehalten werden, gehen alle Anmeldungen verloren, wenn der Server neu gestartet wird.
-   Ein Standardbenutzer `admin` mit dem Passwort `admin` wird beim ersten Start und der Initialisierung der Datenbank angelegt.

## üìÅ Projektstruktur

```
.
‚îú‚îÄ‚îÄ prisma/          # Prisma schema and database migrations
‚îú‚îÄ‚îÄ public/          # Static assets (images, documents, fonts)
‚îú‚îÄ‚îÄ server/          # Server-side code (controllers, utils, server.cjs)
‚îú‚îÄ‚îÄ src/             # Frontend source code (HTML, CSS, JS for bot, admin, dash, login, view)
‚îú‚îÄ‚îÄ test/            # Test files and mocks
‚îú‚îÄ‚îÄ .env             # Environment configuration (copy from .env.example)
‚îú‚îÄ‚îÄ AGENTS.md        # Project-specific documentation for AI assistants
‚îú‚îÄ‚îÄ package.json     # Dependencies and scripts
‚îî‚îÄ‚îÄ README.md        # This file
```

## üìù API-Endpunkte (√úbersicht)

Die Anwendung stellt verschiedene API-Endpunkte bereit:

-   **√ñffentliche API:**
    -   `POST /api/chat`: Sendet eine Anfrage an den KI-Chatbot.
    -   `GET /api/suggestions`: Ruft Vorschl√§ge f√ºr den Chat ab.
-   **Admin-API (`/api/admin/`):**
    -   Endpunkte zur Verwaltung von Eintr√§gen, Benutzern, Feedback, Bildern und mehr. Erfordert Authentifizierung.
-   **Dashboard-API (`/api/dashboard/`):**
    -   Endpunkte zur Bereitstellung von Daten f√ºr das Monitoring-Dashboard. Erfordert Authentifizierung.
-   **Authentifizierungs-API:**
    -   `POST /api/login`: Authentifiziert einen Benutzer und startet eine Sitzung.
    -   `POST /api/logout`: Beendet die aktuelle Sitzung.

## üõ°Ô∏è Sicherheit

-   **Helmet:** Sch√ºtzt die Anwendung durch das Setzen verschiedener sicherheitsrelevanter HTTP-Header.
-   **Rate Limiting:** Begrenzt die Anzahl der Anfragen an die API, um Missbrauch zu verhindern. F√ºr die Anmelde-Endpunkte gelten strengere Limits.

## ü™µ Logging

Benutzeraktionen im Admin-Panel (wie Anmeldungen, Inhaltserstellung und -l√∂schung) werden in der Datei `logs/audit.log` protokolliert, um die Nachverfolgbarkeit zu gew√§hrleisten.

## üß™ Tests

Die Anwendung enth√§lt Unit- und Integrationstests mit Jest.

- **Tests ausf√ºhren (interaktiv w√§hlen .env oder .env.test, defaults to .env in 10s):**
  ```bash
  npm test
  ```

- **Tests direkt mit Jest (ohne Prompt, verwendet .env):**
  ```bash
  npm run test:direct
  ```

- **Tests mit Test-Umgebungsvariablen (.env.test):**
  ```bash
  npm run test:env
  ```

- **Testabdeckung generieren:**
  ```bash
  npm run test:coverage
  ```

Stellen Sie sicher, dass `.env` oder `.env.test` vorhanden ist. Die Tests pr√ºfen nur konfigurierte optionale Abh√§ngigkeiten (z. B. nur ChromaDB, wenn `VECTOR_DB_TYPE=chroma` gesetzt ist).

## üîß Troubleshooting

- **Server startet nicht:** √úberpr√ºfen Sie die `.env`-Datei auf korrekte Konfiguration (z. B. `AI_API_KEY`, `DATABASE_URL`).
- **Datenbankfehler:** F√ºhren Sie `npx prisma migrate dev` aus, um Migrationen anzuwenden.
- **Vite-Dev-Server:** Verwenden Sie `timeout 10s npm run dev` f√ºr Tests, um Blockierungen zu vermeiden.
- **Nginx-Proxy:** Stellen Sie sicher, dass Nginx auf IPv4 bindet (`127.0.0.1:3000`), um 502-Fehler zu vermeiden.
- **Vector DB Sync:** Bei Problemen mit der Vektor-Datenbank f√ºhren Sie `node scripts/migrate_to_prisma.js` aus, um alte Daten zu migrieren.

F√ºr detaillierte Logs pr√ºfen Sie `logs/audit.log` und Konsolen-Ausgaben. Projekt-spezifische Details und Konfigurationstipps finden Sie in `AGENTS.md`.

## üê≥ Produktive Bereitstellung mit Docker

F√ºr eine einfache und isolierte Bereitstellung auf einem nackten Debian- oder Ubuntu-Server verwenden Sie Docker. Dies vermeidet manuelle Installation von Node.js, PostgreSQL usw. und stellt alles in Containern bereit.

### Voraussetzungen
- Debian oder Ubuntu Server (nackt, ohne vorinstallierte Software).
- Root- oder sudo-Zugang.

### Schritt-f√ºr-Schritt-Anleitung

1. **Server vorbereiten:**
   ```bash
   sudo apt update && sudo apt upgrade -y
   sudo apt install -y curl git
   ```

2. **Docker installieren:**
   ```bash
   curl -fsSL https://get.docker.com -o get-docker.sh
   sudo sh get-docker.sh
   sudo usermod -aG docker $USER  # Optional: Aktueller User zu Docker-Gruppe hinzuf√ºgen (nach Logout neu anmelden)
   ```

3. **Projekt klonen:**
   ```bash
   git clone <repository-url> htw-abc-ai-bot
   cd htw-abc-ai-bot
   ```

4. **Umgebung konfigurieren:**
   ```bash
   cp .env.example .env
   nano .env  # Bearbeiten: AI_API_KEY, DATABASE_URL (bleibt postgresql://user:password@db:5432/hochschul_abc), etc.
   ```

5. **Docker-Container starten:**
   ```bash
   docker compose up -d --build
   ```
   - Dies baut das Image, startet App (Port 3000) und PostgreSQL (Port 5432), initialisiert die DB automatisch.
   - App l√§uft unter `http://server-ip:3000`.

6. **Nginx als Reverse-Proxy einrichten (empfohlen f√ºr Produktion):**
   ```bash
   sudo apt install -y nginx
   sudo nano /etc/nginx/sites-available/htw-abc-ai-bot
   ```
   F√ºgen Sie hinzu:
   ```nginx
   server {
       listen 80;
       server_name your-domain.com;  # Ersetzen durch echte Domain

       location / {
           proxy_pass http://127.0.0.1:3000;
           proxy_set_header Host $host;
           proxy_set_header X-Real-IP $remote_addr;
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
           proxy_set_header X-Forwarded-Proto $scheme;
       }
   }
   ```
   Aktivieren und Nginx neu starten:
   ```bash
   sudo ln -s /etc/nginx/sites-available/htw-abc-ai-bot /etc/nginx/sites-enabled/
   sudo nginx -t
   sudo systemctl restart nginx
   ```

7. **SSL mit Let's Encrypt (optional):**
   ```bash
   sudo apt install -y certbot python3-certbot-nginx
   sudo certbot --nginx -d your-domain.com
   ```

8. **√úberpr√ºfen und warten:**
   - App initialisiert DB beim ersten Start (kann 1-2 Min. dauern).
   - Logs: `docker compose logs -f app`
   - Stoppen: `docker compose down`
   - Updates: `git pull && docker compose up -d --build`

**Hinweise:**
- Volumes f√ºr DB (`postgres_data`) und Uploads (`./uploads`, `./backups`) bleiben persistent.
- F√ºr Sicherheit: `.env` nicht im Container-Image (hier external via env_file m√∂glich, aber aktuell kopiert).
- Bei Port-Konflikten: √Ñndern Sie Ports in `docker-compose.yml`.
